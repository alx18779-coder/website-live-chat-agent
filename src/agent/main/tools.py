"""
LangGraph Agent å·¥å…·

å®šä¹‰ Agent å¯ä»¥è°ƒç”¨çš„å·¥å…·ï¼ˆçŸ¥è¯†åº“æ£€ç´¢ã€å†å²å¯¹è¯æ£€ç´¢ç­‰ï¼‰ã€‚
"""

import logging
from typing import Any

from langchain_core.tools import tool
from pydantic import BaseModel, Field

from src.services.llm_factory import create_embeddings
from src.services.milvus_service import milvus_service

logger = logging.getLogger(__name__)


class KnowledgeSearchInput(BaseModel):
    """çŸ¥è¯†åº“æ£€ç´¢å·¥å…·è¾“å…¥"""

    query: str = Field(description="è¦æœç´¢çš„é—®é¢˜æˆ–å…³é”®è¯")
    top_k: int = Field(default=3, ge=1, le=10, description="è¿”å›ç»“æœæ•°é‡")


class HistorySearchInput(BaseModel):
    """å†å²å¯¹è¯æ£€ç´¢å·¥å…·è¾“å…¥"""

    query: str = Field(description="è¦æœç´¢çš„å†å²å¯¹è¯å…³é”®è¯")
    session_id: str = Field(description="ä¼šè¯ID")
    top_k: int = Field(default=2, ge=1, le=5, description="è¿”å›ç»“æœæ•°é‡")


@tool("knowledge_search", args_schema=KnowledgeSearchInput, return_direct=False)
async def knowledge_search_tool(query: str, top_k: int = 3) -> str:
    """
    æœç´¢ç½‘ç«™çŸ¥è¯†åº“

    ä» Milvus å‘é‡æ•°æ®åº“æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„çŸ¥è¯†åº“æ–‡æ¡£ã€‚
    é€‚ç”¨äºå›ç­”å…³äºäº§å“ã€FAQã€æ”¿ç­–ç­‰ç½‘ç«™ç‰¹å®šé—®é¢˜ã€‚

    Args:
        query: ç”¨æˆ·é—®é¢˜æˆ–å…³é”®è¯
        top_k: è¿”å›ç»“æœæ•°é‡

    Returns:
        æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœå­—ç¬¦ä¸²
    """
    try:
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        embeddings = create_embeddings()

        # æˆªæ–­æŸ¥è¯¢æ–‡æœ¬åˆ°512 tokensä»¥å†…ï¼ˆæŸ¥è¯¢é€šå¸¸ä¸éœ€è¦åˆ†å—ï¼‰
        from src.core.utils import truncate_text_to_tokens
        truncated_query = truncate_text_to_tokens(query, max_tokens=512)
        query_embedding = await embeddings.aembed_query(truncated_query)

        # æ·»åŠ æ—¥å¿—æç¤º
        if len(query) != len(truncated_query):
            logger.warning(
                f"Query truncated from {len(query)} to {len(truncated_query)} chars "
                f"to fit 512 token limit"
            )

        # æ£€ç´¢çŸ¥è¯†åº“ï¼ˆä½¿ç”¨æ–°çš„Repositoryï¼‰
        from src.repositories import get_knowledge_repository
        
        knowledge_repo = get_knowledge_repository()
        knowledge_results = await knowledge_repo.search(
            query_embedding=query_embedding,
            top_k=top_k,
        )

        if not knowledge_results:
            return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for i, result in enumerate(knowledge_results, 1):
            metadata = result.metadata
            title = metadata.get("title", "æœªå‘½åæ–‡æ¡£")
            formatted_results.append(
                f"[æ–‡æ¡£{i}] {title} (ç›¸ä¼¼åº¦: {result.score:.2f})\n{result.text}"
            )

        logger.info(f"ğŸ” Knowledge search: found {len(knowledge_results)} results for '{query}'")
        return "\n\n".join(formatted_results)

    except Exception as e:
        logger.error(f"Knowledge search failed: {e}")
        return f"çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {str(e)}"


@tool("history_search", args_schema=HistorySearchInput, return_direct=False)
async def history_search_tool(query: str, session_id: str, top_k: int = 2) -> str:
    """
    æœç´¢å†å²å¯¹è¯è®°å½•

    ä» Milvus æ£€ç´¢å½“å‰ä¼šè¯çš„å†å²å¯¹è¯ï¼Œç”¨äºç†è§£ä¸Šä¸‹æ–‡ã€‚

    Args:
        query: æœç´¢å…³é”®è¯
        session_id: ä¼šè¯ID
        top_k: è¿”å›ç»“æœæ•°é‡

    Returns:
        æ ¼å¼åŒ–çš„å†å²å¯¹è¯å­—ç¬¦ä¸²
    """
    try:
        # è·å–ä¼šè¯å†å²ï¼ˆä½¿ç”¨æ–°çš„Repositoryï¼‰
        from src.repositories import get_history_repository
        
        history_repo = get_history_repository()
        history_results = await history_repo.search_by_session(
            session_id=session_id,
            limit=top_k,
        )

        if not history_results:
            return "æœªæ‰¾åˆ°ç›¸å…³å†å²å¯¹è¯ã€‚"

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for result in history_results:
            role = "ç”¨æˆ·" if result.role == "user" else "åŠ©æ‰‹"
            formatted_results.append(f"{role}: {result.text}")

        logger.info(f"ğŸ“œ History search: found {len(history_results)} messages for session {session_id}")
        return "\n".join(formatted_results)

    except Exception as e:
        logger.error(f"History search failed: {e}")
        return f"å†å²å¯¹è¯æ£€ç´¢å¤±è´¥: {str(e)}"


# å·¥å…·åˆ—è¡¨ï¼ˆä¾› LangGraph ä½¿ç”¨ï¼‰
AGENT_TOOLS = [
    knowledge_search_tool,
    # history_search_tool,  # å¯é€‰ï¼šå¦‚æœéœ€è¦è·¨ä¼šè¯æ£€ç´¢
]


async def search_knowledge_for_agent(query: str, top_k: int = 3) -> list[dict[str, Any]]:
    """
    ä¾› Agent èŠ‚ç‚¹ç›´æ¥è°ƒç”¨çš„çŸ¥è¯†åº“æ£€ç´¢å‡½æ•°

    ä¸ä½¿ç”¨ @tool è£…é¥°å™¨ï¼Œç›´æ¥è¿”å›ç»“æ„åŒ–æ•°æ®ã€‚

    Args:
        query: æŸ¥è¯¢é—®é¢˜
        top_k: è¿”å›ç»“æœæ•°é‡

    Returns:
        æ£€ç´¢ç»“æœåˆ—è¡¨
    """
    try:
        embeddings = create_embeddings()
        # æˆªæ–­æŸ¥è¯¢æ–‡æœ¬åˆ°512 tokensä»¥å†…
        from src.core.utils import truncate_text_to_tokens
        truncated_query = truncate_text_to_tokens(query, max_tokens=512)
        query_embedding = await embeddings.aembed_query(truncated_query)

        # æ·»åŠ æ—¥å¿—æç¤º
        if len(query) != len(truncated_query):
            logger.warning(f"Query truncated from {len(query)} to {len(truncated_query)} chars to fit 512 token limit")

        # ä½¿ç”¨æ–°çš„Repository
        from src.repositories import get_knowledge_repository
        
        knowledge_repo = get_knowledge_repository()
        knowledge_results = await knowledge_repo.search(
            query_embedding=query_embedding,
            top_k=top_k,
        )

        logger.info(f"ğŸ” Retrieved {len(knowledge_results)} documents for: {query}")
        
        # è½¬æ¢ä¸ºdictæ ¼å¼ä»¥ä¿æŒå‘åå…¼å®¹
        return [
            {
                "text": r.text,
                "score": r.score,
                "metadata": r.metadata,
            }
            for r in knowledge_results
        ]

    except Exception as e:
        logger.error(f"Knowledge search failed: {e}")
        return []

